{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   questions  5000 non-null   object\n",
      " 1   a          5000 non-null   object\n",
      " 2   b          5000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 117.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "file_name = 'data/Travel-Dataset-5000--master/5000TravelQuestionsDataset.xlsx'\n",
    "col_names = ['questions', 'a', 'b']\n",
    "dataset = pd.read_excel(file_name, header=None, names=col_names)\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TTD', 'TGU', 'ACM', 'TRS', 'WTH', 'FOD', 'ENT', 'TGU\\n', 'TTD\\n',\n",
       "       '\\nENT'], dtype=object)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['a'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TTDSIG', 'TTDOTH', 'TGUHEA', 'ACMOTH', 'TRSTRN', 'TGUBAN',\n",
       "       'WTHTMP', 'TGUNEI', 'TTDSPO', 'ACMAPA', 'TRSOTH', 'TRSAIR',\n",
       "       'TRSROU', 'TGUOTH', 'ACMRES', 'ACMBUN', 'TRSCRS', 'WTHDRC',\n",
       "       'TRSRNT', 'TGUTOP', 'FODOTH', 'TGUVIS', 'FODAUT', 'TTDTRI',\n",
       "       'TGUPLN', 'TRSTAX', 'WTHOTH', 'TRSBUS', 'ACMHOT', 'TGULUG',\n",
       "       'FODBAK', 'TTDSPA', 'FODBRE', 'TGUATT', 'ENTCLB', 'TGUAVE',\n",
       "       'TGUTEL', 'TGUCIG', 'TTDSHP', 'TRSTCD', 'ACMBEA', 'FODCOT',\n",
       "       'TGUAPT', 'TRSLIC', 'TGULAU', 'TTDGYM', 'FODCAT', 'FODBAR',\n",
       "       'TGUHOL', 'ENTFES', 'TGURUL', 'TGURES', 'WTHTMP\\n', 'ACMCAR',\n",
       "       'FODFMA', 'ENTSHW', 'TRSGAS', '\\nTGULAU', 'TRSOTH\\n', 'WTHSNW',\n",
       "       'ENTMUS', 'ENTSPO', 'FODBAK\\n', 'TRSAIR\\n', 'TGUWEB', 'TRSDRV',\n",
       "       'FODFCA', 'TGUCIG\\n', 'ENTOTH', 'TTDOTH\\n', 'WTHOTH\\n', 'TTDSIG\\n',\n",
       "       'TGUOTH\\n', 'TTDSHP\\n', 'TRSROU\\n', 'TTDSPO\\n', '\\nACMOTH',\n",
       "       'ACMOTH\\n', '\\nWTHOTH'], dtype=object)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['b'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the special things we (husband and me...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the companies which organize shark fe...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDOTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it safe for female traveller to go alone to...</td>\n",
       "      <td>TGU</td>\n",
       "      <td>TGUHEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the best places around Cape Town for ...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the best places to stay for a family ...</td>\n",
       "      <td>ACM</td>\n",
       "      <td>ACMOTH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions    a       b\n",
       "0  What are the special things we (husband and me...  TTD  TTDSIG\n",
       "1  What are the companies which organize shark fe...  TTD  TTDOTH\n",
       "2  Is it safe for female traveller to go alone to...  TGU  TGUHEA\n",
       "3  What are the best places around Cape Town for ...  TTD  TTDSIG\n",
       "4  What are the best places to stay for a family ...  ACM  ACMOTH"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   questions  5000 non-null   object\n",
      " 1   a          5000 non-null   object\n",
      " 2   b          5000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test_id = 2\n",
    "dataset['questions'].dropna(inplace=True)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the best beaches for shelling in CapeTown?'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id = 9\n",
    "dataset['questions'][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what are the best beaches for shelling in capetown?'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Applies some pre-processing on the given text.\n",
    "\n",
    "    Steps :\n",
    "    - Removing HTML tags\n",
    "    - Removing punctuation\n",
    "    - Lowering text\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # remove the characters [\\], ['] and [\"]\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)    \n",
    "    \n",
    "    # convert text to lowercase\n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    # replace punctuation characters with spaces\n",
    "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "\n",
    "    return text\n",
    "\n",
    "dataset['clean_questions'] = [lowercase(question) for question in dataset['questions']]\n",
    "dataset['clean_questions'][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lowercase(x):\n",
    "#     return x.lower()\n",
    "\n",
    "# dataset['questions'] = [clean_text(question) for question in dataset['questions']]\n",
    "# dataset['lc_questions'][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "\n",
    "# def remove_punctuation(x):\n",
    "#     return \"\".join([char for char in x if char not in string.punctuation])\n",
    "\n",
    "# dataset['questions'] = [remove_punctuation(question) for question in dataset['questions']]\n",
    "# dataset['questions'][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# stop_words = stopwords.words('english')\n",
    "# from nltk import word_tokenize\n",
    "\n",
    "# def remove_stopwords(x):\n",
    "#     words = word_tokenize(x)\n",
    "#     return \" \".join([word for word in words if word not in stop_words])\n",
    "\n",
    "# dataset['questions'] = [remove_stopwords(question) for question in dataset['questions']]\n",
    "# dataset['questions'][test_id]\n",
    "# print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem.porter import PorterStemmer\n",
    "# porter = PorterStemmer()\n",
    "# def stemming(x):\n",
    "#     filtered_words = word_tokenize(x['questions'])\n",
    "#     stemmed = [porter.stem(word) for word in filtered_words]\n",
    "#     return \" \".join(stemmed)\n",
    "\n",
    "# dataset['questions'] = [remove_stopwords(question) for question in dataset['questions']]\n",
    "# dataset['questions'][test_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize and create BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what are the best beach for shelling in capetown ?'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(x):\n",
    "    filtered_words = nltk.word_tokenize(x)\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    return \" \".join(lemmatized)\n",
    "\n",
    "dataset['lem_questions'] = [lemmatize(question) for question in dataset['clean_questions']]\n",
    "dataset['lem_questions'][test_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WP VBP DT JJS NNS IN VBG IN NNP .'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "def pos_tagging(x):\n",
    "    words = nltk.word_tokenize(x)\n",
    "    lst = [ r[1] for r in pos_tag(words)] \n",
    "    return ' '.join(lst)\n",
    "\n",
    "dataset['pos_questions'] = [pos_tagging(question) for question in dataset['questions']]\n",
    "dataset['pos_questions'][test_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dulan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CapeTown'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "\n",
    "def get_continuous_chunks(text):\n",
    "    chunked = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    prev = None\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for i in chunked:\n",
    "        if type(i) == Tree:\n",
    "            current_chunk.append(\" \".join([token for token, pos in i.leaves()]))\n",
    "        elif current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "                continuous_chunk.append(named_entity)\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    if continuous_chunk:\n",
    "        named_entity = \" \".join(current_chunk)\n",
    "        if named_entity not in continuous_chunk:\n",
    "            continuous_chunk.append(named_entity)\n",
    "    \n",
    "    def remove_null(x):\n",
    "        if '' in x:\n",
    "            x.remove('')\n",
    "        return x\n",
    "\n",
    "    lst = remove_null(continuous_chunk)\n",
    "    return ' '.join(lst)\n",
    "\n",
    "txt = \"Barack Obama is a great person.\" \n",
    "txt2 = \"Who is Dulan?\"\n",
    "print (get_continuous_chunks(txt2))\n",
    "\n",
    "\n",
    "\n",
    "dataset['ne_questions'] = [get_continuous_chunks(question) for question in dataset['questions']]\n",
    "dataset['ne_questions'][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1090)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def get_count_vect(documents):\n",
    "    vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "    X = vectorizer.fit_transform(documents).toarray()\n",
    "    print(X.shape)\n",
    "    return X\n",
    "\n",
    "print(get_count_vect(dataset['questions']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM - Normal train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 5000)\n",
      "Fold - 1 - SVM Accuracy Score ->  - 83.20\n",
      "(4500, 5000)\n",
      "Fold - 2 - SVM Accuracy Score ->  - 84.60\n",
      "(4500, 5000)\n",
      "Fold - 3 - SVM Accuracy Score ->  - 81.00\n",
      "(4500, 5000)\n",
      "Fold - 4 - SVM Accuracy Score ->  - 82.00\n",
      "(4500, 5000)\n",
      "Fold - 5 - SVM Accuracy Score ->  - 83.40\n",
      "(4500, 5000)\n",
      "Fold - 6 - SVM Accuracy Score ->  - 83.80\n",
      "(4500, 5000)\n",
      "Fold - 7 - SVM Accuracy Score ->  - 84.00\n",
      "(4500, 5000)\n",
      "Fold - 8 - SVM Accuracy Score ->  - 84.80\n",
      "(4500, 5000)\n",
      "Fold - 9 - SVM Accuracy Score ->  - 83.60\n",
      "(4500, 5000)\n",
      "Fold - 10 - SVM Accuracy Score ->  - 83.40\n",
      "Mean 83.38 Std 1.08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = dataset['lem_questions'],dataset['a']\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "tfidf.fit(X)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "accuracies = []\n",
    "for train_index, test_index in cv.split(X):\n",
    "    fold += 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    y_train_e = le.transform(y_train)\n",
    "    y_test_e = le.transform(y_test)\n",
    "    \n",
    "    X_train_tfidf = tfidf.transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    print(X_train_tfidf.shape)\n",
    "    \n",
    "    SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "    SVM.fit(X_train_tfidf,y_train_e)\n",
    "    predictions_SVM = SVM.predict(X_test_tfidf)\n",
    "    acc = accuracy_score(predictions_SVM, y_test_e)*100\n",
    "    accuracies.append(acc)\n",
    "    print(\"Fold - {} - {} - {:.2f}\".format(fold, \"SVM Accuracy Score -> \",acc))\n",
    "    \n",
    "print(\"Mean {:.2f} Std {:.2f}\".format(np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 31)\n",
      "Fold - 1 - SVM Accuracy Score ->  - 38.80\n",
      "(4500, 31)\n",
      "Fold - 2 - SVM Accuracy Score ->  - 40.00\n",
      "(4500, 31)\n",
      "Fold - 3 - SVM Accuracy Score ->  - 39.80\n",
      "(4500, 31)\n",
      "Fold - 4 - SVM Accuracy Score ->  - 42.20\n",
      "(4500, 31)\n",
      "Fold - 5 - SVM Accuracy Score ->  - 41.80\n",
      "(4500, 31)\n",
      "Fold - 6 - SVM Accuracy Score ->  - 40.00\n",
      "(4500, 31)\n",
      "Fold - 7 - SVM Accuracy Score ->  - 39.40\n",
      "(4500, 31)\n",
      "Fold - 8 - SVM Accuracy Score ->  - 37.00\n",
      "(4500, 31)\n",
      "Fold - 9 - SVM Accuracy Score ->  - 40.20\n",
      "(4500, 31)\n",
      "Fold - 10 - SVM Accuracy Score ->  - 33.80\n",
      "Mean 39.30 Std 2.29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = dataset['pos_questions'],dataset['a']\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "tfidf.fit(X)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "accuracies = []\n",
    "for train_index, test_index in cv.split(X):\n",
    "    fold += 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    y_train_e = le.transform(y_train)\n",
    "    y_test_e = le.transform(y_test)\n",
    "    \n",
    "    X_train_tfidf = tfidf.transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    print(X_train_tfidf.shape)\n",
    "    \n",
    "    SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "    SVM.fit(X_train_tfidf,y_train_e)\n",
    "    predictions_SVM = SVM.predict(X_test_tfidf)\n",
    "    acc = accuracy_score(predictions_SVM, y_test_e)*100\n",
    "    accuracies.append(acc)\n",
    "    print(\"Fold - {} - {} - {:.2f}\".format(fold, \"SVM Accuracy Score -> \",acc))\n",
    "    \n",
    "print(\"Mean {:.2f} Std {:.2f}\".format(np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 26)\n",
      "[[1 1 0 ... 0 1 0]\n",
      " [0 0 0 ... 1 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(5000, 26)\n",
      "(5000, 322)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5000, 5348)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from scipy.sparse import coo_matrix, csr_matrix, hstack\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(dataset['a'])\n",
    "\n",
    "X_lem = dataset['lem_questions']\n",
    "tfidf_lem = TfidfVectorizer(max_features=5000)\n",
    "tfidf_lem.fit(X_lem)\n",
    "\n",
    "X_pos = dataset['pos_questions']\n",
    "# tfidf = TfidfVectorizer(max_features=50)\n",
    "# tfidf.fit(X_pos)\n",
    "\n",
    "X_ne = dataset['ne_questions']\n",
    "print(get_count_vect(X_pos))\n",
    "\n",
    "print(type(tfidf_lem.transform(X_lem)))\n",
    "XX = csr_matrix(hstack([tfidf_lem.transform(X_lem) ,get_count_vect(X_pos), get_count_vect(X_ne)]))\n",
    "print(type(XX))\n",
    "XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['lem_questions'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 5348)\n",
      "Fold - 1 - SVM Accuracy Score ->  - 79.20\n",
      "(4500, 5348)\n",
      "Fold - 2 - SVM Accuracy Score ->  - 82.40\n",
      "(4500, 5348)\n",
      "Fold - 3 - SVM Accuracy Score ->  - 79.60\n",
      "(4500, 5348)\n",
      "Fold - 4 - SVM Accuracy Score ->  - 79.60\n",
      "(4500, 5348)\n",
      "Fold - 5 - SVM Accuracy Score ->  - 80.80\n",
      "(4500, 5348)\n",
      "Fold - 6 - SVM Accuracy Score ->  - 81.60\n",
      "(4500, 5348)\n",
      "Fold - 7 - SVM Accuracy Score ->  - 81.20\n",
      "(4500, 5348)\n",
      "Fold - 8 - SVM Accuracy Score ->  - 79.00\n",
      "(4500, 5348)\n",
      "Fold - 9 - SVM Accuracy Score ->  - 80.80\n",
      "(4500, 5348)\n",
      "Fold - 10 - SVM Accuracy Score ->  - 79.80\n",
      "Mean 80.40 Std 1.07\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "accuracies = []\n",
    "for train_index, test_index in cv.split(XX):\n",
    "    fold += 1\n",
    "    X_train, X_test = XX[train_index], XX[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    print(X_train.shape)\n",
    "\n",
    "    \n",
    "    SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "    SVM.fit(X_train,y_train)\n",
    "    predictions_SVM = SVM.predict(X_test)\n",
    "    acc = accuracy_score(predictions_SVM, y_test)*100\n",
    "    accuracies.append(acc)\n",
    "    print(\"Fold - {} - {} - {:.2f}\".format(fold, \"SVM Accuracy Score -> \",acc))\n",
    "    \n",
    "print(\"Mean {:.2f} Std {:.2f}\".format(np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"fasttext_skipgram_travel_questions.bin\" - model loaded\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import os\n",
    "model_name='fasttext_skipgram_travel_questions.bin'\n",
    "\n",
    "if not os.path.exists(model_name):\n",
    "    dataset['questions'].to_csv('questions.txt', sep='.', header=False, index=False)\n",
    "    model = fasttext.train_unsupervised('questions.txt', model='skipgram')\n",
    "    model.save_model(model_name)\n",
    "    print(\"Model saved as {}\".format(model_name))\n",
    "else:\n",
    "    print(\"\\\"{}\\\" - model loaded\".format(model_name))\n",
    "    model = fasttext.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[ 7.14299676e-05  2.32432321e-01 -2.40925714e-01 -1.74242929e-01\n",
      " -4.39231321e-02  2.45131522e-01 -2.27550954e-01  3.51612344e-02\n",
      " -1.35040674e-02  6.65467754e-02  1.80292074e-02  4.08698320e-02\n",
      "  1.47805631e-01 -4.09955978e-02  1.14978559e-01 -4.33138423e-02\n",
      " -1.80182517e-01 -1.58651307e-01 -2.19959438e-01 -3.89570266e-01\n",
      " -1.93506658e-01  3.53299528e-01  1.32871151e-01 -1.09432288e-01\n",
      " -7.85724819e-02 -3.23186889e-02  2.63973564e-01 -2.09144980e-01\n",
      "  1.40900716e-01  4.18550760e-01  1.00273587e-01 -2.01780409e-01\n",
      "  1.07219130e-01 -2.64418364e-01 -1.07324362e-01  1.89055175e-01\n",
      " -1.23978466e-01 -6.86219707e-02 -1.82332143e-01 -1.99690199e-04\n",
      "  1.38345420e-01  3.61972660e-01 -8.87458958e-03 -5.23991622e-02\n",
      "  2.63315067e-02 -2.84253269e-01  5.83582968e-02 -1.83719546e-01\n",
      " -7.05709029e-03  1.42239183e-01  3.36414427e-02  1.66355848e-01\n",
      " -1.53241102e-02  1.18326567e-01  2.25987196e-01  6.47004843e-02\n",
      " -4.14141901e-02 -3.55386846e-02 -5.03547899e-02  3.76824252e-02\n",
      "  8.85521099e-02  1.40455216e-01  2.00291812e-01  2.34027311e-01\n",
      " -8.95774215e-02 -1.11320373e-02 -4.39670794e-02  1.80168562e-02\n",
      " -5.82079031e-02 -1.83240026e-01  6.60962611e-02  2.47135133e-01\n",
      "  8.99827555e-02  1.05127603e-01 -3.24992128e-02 -1.20224811e-01\n",
      " -5.53014725e-02  3.74246985e-01 -9.00930911e-02  3.26454849e-03\n",
      " -1.21370435e-01  2.73503542e-01  2.39274755e-01  6.56881034e-02\n",
      "  2.70447433e-01 -4.25674096e-02 -1.96763724e-01  8.71547312e-02\n",
      " -1.65535927e-01 -3.29523310e-02  2.30019256e-01  2.70924300e-01\n",
      "  2.60625213e-01 -1.21415332e-01 -1.77936852e-01 -9.13724005e-02\n",
      " -1.90188944e-01  2.83253402e-01 -2.09534943e-01  3.90715264e-02]\n",
      "1203 100\n"
     ]
    }
   ],
   "source": [
    "print('hello' in model.words)   # list of words in dictionary\n",
    "print(model['hello']) # get the vector of the word 'king'\n",
    "print(len(model.words), len(model['hello']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim Doc2Vec - Using Sentence Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(dataset['questions'])]\n",
    "model = Doc2Vec(documents, vector_size=1000, window=2, min_count=1, workers=4)\n",
    "\n",
    "def doc2vec(x):\n",
    "    return np.array(model.infer_vector(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec('hello world').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _id = 3\n",
    "# vector = model.infer_vector(dataset['questions'][_id].split(' '))\n",
    "# print(vector)\n",
    "# print(dataset['questions'][_id])\n",
    "\n",
    "dataset['doc2vec_questions'] = np.array([doc2vec(question) for question in dataset['questions']])\n",
    "dataset['doc2vec_questions'][test_id]\n",
    "dataset['doc2vec_questions'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1000)\n",
      "(4500, 1000)\n",
      "Fold - 1 - SVM Accuracy Score ->  - 21.20\n",
      "(4500, 1000)\n",
      "Fold - 2 - SVM Accuracy Score ->  - 27.80\n",
      "(4500, 1000)\n",
      "Fold - 3 - SVM Accuracy Score ->  - 25.20\n",
      "(4500, 1000)\n",
      "Fold - 4 - SVM Accuracy Score ->  - 23.40\n",
      "(4500, 1000)\n",
      "Fold - 5 - SVM Accuracy Score ->  - 22.80\n",
      "(4500, 1000)\n",
      "Fold - 6 - SVM Accuracy Score ->  - 24.40\n",
      "(4500, 1000)\n",
      "Fold - 7 - SVM Accuracy Score ->  - 22.00\n",
      "(4500, 1000)\n",
      "Fold - 8 - SVM Accuracy Score ->  - 24.00\n",
      "(4500, 1000)\n",
      "Fold - 9 - SVM Accuracy Score ->  - 26.20\n",
      "(4500, 1000)\n",
      "Fold - 10 - SVM Accuracy Score ->  - 22.60\n",
      "Mean 23.96 Std 1.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "XX = np.array([doc2vec(question) for question in dataset['questions']])\n",
    "print(XX.shape)\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "accuracies = []\n",
    "for train_index, test_index in cv.split(XX):\n",
    "    fold += 1\n",
    "    X_train, X_test = XX[train_index], XX[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    print(X_train.shape)\n",
    "\n",
    "    \n",
    "    SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "    SVM.fit(X_train,y_train)\n",
    "    predictions_SVM = SVM.predict(X_test)\n",
    "    acc = accuracy_score(predictions_SVM, y_test)*100\n",
    "    accuracies.append(acc)\n",
    "    print(\"Fold - {} - {} - {:.2f}\".format(fold, \"SVM Accuracy Score -> \",acc))\n",
    "    \n",
    "print(\"Mean {:.2f} Std {:.2f}\".format(np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83.39999999999999,\n",
       " 83.8,\n",
       " 80.2,\n",
       " 82.39999999999999,\n",
       " 82.8,\n",
       " 83.39999999999999,\n",
       " 82.8,\n",
       " 84.6,\n",
       " 83.6,\n",
       " 82.39999999999999]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.std([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "data = ['data']\n",
    "model = gensim.models.Word2Vec(data, min_count=1, sg=1, window = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A NN classifier s.a. an LSTM for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 20\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5584 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(dataset['questions'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 7, 2, 321, 105, 31, 1838, 17, 68, 9, 20, 71, 6, 194, 48, 32, 22, 376, 111]\n",
      "Shape of data tensor: (5000, 20)\n",
      "Shape of label tensor: (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X = tokenizer.texts_to_sequences(dataset['questions'].values)\n",
    "print(X[0])\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)\n",
    "\n",
    "y_nn = pd.get_dummies(dataset['a']).values\n",
    "print('Shape of label tensor:', y_nn.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 20) for input Tensor(\"embedding_2_input:0\", shape=(None, 20), dtype=float32), but it was called on an input with incompatible shape (None, 1000).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 20) for input Tensor(\"embedding_2_input:0\", shape=(None, 20), dtype=float32), but it was called on an input with incompatible shape (None, 1000).\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.8625 - accuracy: 0.2343WARNING:tensorflow:Model was constructed with shape (None, 20) for input Tensor(\"embedding_2_input:0\", shape=(None, 20), dtype=float32), but it was called on an input with incompatible shape (None, 1000).\n",
      "64/64 [==============================] - 109s 2s/step - loss: 1.8625 - accuracy: 0.2343 - val_loss: 1.8829 - val_accuracy: 0.0756\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 115s 2s/step - loss: 1.7757 - accuracy: 0.2551 - val_loss: 1.9834 - val_accuracy: 0.0756\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 124s 2s/step - loss: 1.7746 - accuracy: 0.2612 - val_loss: 2.0528 - val_accuracy: 0.0756\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 125s 2s/step - loss: 1.7757 - accuracy: 0.2627 - val_loss: 1.9533 - val_accuracy: 0.0756\n",
      "Epoch 1/5\n",
      "52/64 [=======================>......] - ETA: 23s - loss: 1.7689 - accuracy: 0.2524"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "accuracies = []\n",
    "for train_index, test_index in cv.split(XX):\n",
    "    fold += 1\n",
    "    X_train, X_test = XX[train_index], XX[test_index]\n",
    "    y_train, y_test = y_nn[train_index], y_nn[test_index]\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
