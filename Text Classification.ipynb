{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "# config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.set_virtual_device_configuration(physical_devices[0], [\n",
    "tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   questions  5000 non-null   object\n",
      " 1   a          5000 non-null   object\n",
      " 2   b          5000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 117.3+ KB\n",
      "None\n",
      "['TTD' 'TGU' 'ACM' 'TRS' 'WTH' 'FOD' 'ENT' 'TGU\\n' 'TTD\\n' '\\nENT']\n",
      "What are the companies which organize shark feeding events for scuba divers?\n"
     ]
    }
   ],
   "source": [
    "file_name = 'data/Travel-Dataset-5000--master/5000TravelQuestionsDataset.xlsx'\n",
    "test_id  = 1\n",
    "col_names = ['questions', 'a', 'b']\n",
    "dataset = pd.read_excel(file_name, header=None, names=col_names)\n",
    "dataset['questions'].dropna(inplace=True)\n",
    "print(dataset.info())\n",
    "print(dataset['a'].unique())\n",
    "print(dataset['questions'][test_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what are the companies which organize shark feeding events for scuba divers '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Applies some pre-processing on the given text.\n",
    "\n",
    "    Steps :\n",
    "    - Removing HTML tags\n",
    "    - Removing punctuation\n",
    "    - Lowering text\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # remove the characters [\\], ['] and [\"]\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)    \n",
    "    \n",
    "    # convert text to lowercase\n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    # replace punctuation characters with spaces\n",
    "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "\n",
    "    return text\n",
    "\n",
    "dataset['clean_questions'] = [clean_text(question) for question in dataset['questions']]\n",
    "dataset['clean_questions'][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lowercase(x):\n",
    "#     return x.lower()\n",
    "\n",
    "# dataset['questions'] = [clean_text(question) for question in dataset['questions']]\n",
    "# dataset['lc_questions'][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "\n",
    "# def remove_punctuation(x):\n",
    "#     return \"\".join([char for char in x if char not in string.punctuation])\n",
    "\n",
    "# dataset['questions'] = [remove_punctuation(question) for question in dataset['questions']]\n",
    "# dataset['questions'][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# stop_words = stopwords.words('english')\n",
    "# from nltk import word_tokenize\n",
    "\n",
    "# def remove_stopwords(x):\n",
    "#     words = word_tokenize(x)\n",
    "#     return \" \".join([word for word in words if word not in stop_words])\n",
    "\n",
    "# dataset['questions'] = [remove_stopwords(question) for question in dataset['questions']]\n",
    "# dataset['questions'][test_id]\n",
    "# print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem.porter import PorterStemmer\n",
    "# porter = PorterStemmer()\n",
    "# def stemming(x):\n",
    "#     filtered_words = word_tokenize(x['questions'])\n",
    "#     stemmed = [porter.stem(word) for word in filtered_words]\n",
    "#     return \" \".join(stemmed)\n",
    "\n",
    "# dataset['questions'] = [remove_stopwords(question) for question in dataset['questions']]\n",
    "# dataset['questions'][test_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize and create BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what are the company which organize shark feeding event for scuba diver'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(x):\n",
    "    filtered_words = nltk.word_tokenize(x)\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    return \" \".join(lemmatized)\n",
    "\n",
    "dataset['lem_questions'] = [lemmatize(question) for question in dataset['clean_questions']]\n",
    "dataset['lem_questions'][test_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WP VBP DT NNS WDT VBP NN NN NNS IN NN NNS .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "def pos_tagging(x):\n",
    "    words = nltk.word_tokenize(x)\n",
    "    lst = [ r[1] for r in pos_tag(words)] \n",
    "    return ' '.join(lst)\n",
    "\n",
    "dataset['pos_questions'] = [pos_tagging(question) for question in dataset['questions']]\n",
    "dataset['pos_questions'][test_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dulan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "\n",
    "def get_continuous_chunks(text):\n",
    "    chunked = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    prev = None\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for i in chunked:\n",
    "        if type(i) == Tree:\n",
    "            current_chunk.append(\" \".join([token for token, pos in i.leaves()]))\n",
    "        elif current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "                continuous_chunk.append(named_entity)\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    if continuous_chunk:\n",
    "        named_entity = \" \".join(current_chunk)\n",
    "        if named_entity not in continuous_chunk:\n",
    "            continuous_chunk.append(named_entity)\n",
    "    \n",
    "    def remove_null(x):\n",
    "        if '' in x:\n",
    "            x.remove('')\n",
    "        return x\n",
    "\n",
    "    lst = remove_null(continuous_chunk)\n",
    "    return ' '.join(lst)\n",
    "\n",
    "txt = \"Barack Obama is a great person.\" \n",
    "txt2 = \"Who is Dulan?\"\n",
    "print (get_continuous_chunks(txt2))\n",
    "\n",
    "\n",
    "\n",
    "dataset['ne_questions'] = [get_continuous_chunks(question) for question in dataset['questions']]\n",
    "dataset['ne_questions'][test_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count vectorizer (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1090)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def get_count_vect(documents):\n",
    "    vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "    X = vectorizer.fit_transform(documents).toarray()\n",
    "    print(X.shape)\n",
    "    return X\n",
    "\n",
    "print(get_count_vect(dataset['questions']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head word feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head word tokenizer\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def head_word_tokenizer(text):\n",
    "    head_words = []\n",
    "    for token in nlp(text):\n",
    "        if token.dep_ == \"nsubj\" or token.dep_ == \"nsubjpass\":\n",
    "            head_words.append(token.text)\n",
    "            head_words.append(token.head.text)\n",
    "    return head_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\"] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "head_words_vectorizer = CountVectorizer(tokenizer = head_word_tokenizer,max_features=100,stop_words=stopwords.words('english'))\n",
    "head_words_vector = head_words_vectorizer.fit_transform(dataset[\"questions\"].values).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM - Normal train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 5000)\n",
      "Fold - 1 - SVM Accuracy Score ->  - 83.20\n",
      "(4500, 5000)\n",
      "Fold - 2 - SVM Accuracy Score ->  - 84.80\n",
      "(4500, 5000)\n",
      "Fold - 3 - SVM Accuracy Score ->  - 81.40\n",
      "(4500, 5000)\n",
      "Fold - 4 - SVM Accuracy Score ->  - 81.80\n",
      "(4500, 5000)\n",
      "Fold - 5 - SVM Accuracy Score ->  - 83.40\n",
      "(4500, 5000)\n",
      "Fold - 6 - SVM Accuracy Score ->  - 84.20\n",
      "(4500, 5000)\n",
      "Fold - 7 - SVM Accuracy Score ->  - 83.40\n",
      "(4500, 5000)\n",
      "Fold - 8 - SVM Accuracy Score ->  - 84.40\n",
      "(4500, 5000)\n",
      "Fold - 9 - SVM Accuracy Score ->  - 82.80\n",
      "(4500, 5000)\n",
      "Fold - 10 - SVM Accuracy Score ->  - 82.80\n",
      "Mean 83.22 Std 1.03\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = dataset['lem_questions'],dataset['a']\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "tfidf.fit(X)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "accuracies = []\n",
    "for train_index, test_index in cv.split(X):\n",
    "    fold += 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    y_train_e = le.transform(y_train)\n",
    "    y_test_e = le.transform(y_test)\n",
    "    \n",
    "    X_train_tfidf = tfidf.transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    print(X_train_tfidf.shape)\n",
    "    \n",
    "    SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "    SVM.fit(X_train_tfidf,y_train_e)\n",
    "    predictions_SVM = SVM.predict(X_test_tfidf)\n",
    "    acc = accuracy_score(predictions_SVM, y_test_e)*100\n",
    "    accuracies.append(acc)\n",
    "    print(\"Fold - {} - {} - {:.2f}\".format(fold, \"SVM Accuracy Score -> \",acc))\n",
    "    \n",
    "print(\"Mean {:.2f} Std {:.2f}\".format(np.mean(accuracies), np.std(accuracies)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 31)\n",
      "Fold - 1 - SVM Accuracy Score ->  - 38.80\n",
      "(4500, 31)\n",
      "Fold - 2 - SVM Accuracy Score ->  - 40.00\n",
      "(4500, 31)\n",
      "Fold - 3 - SVM Accuracy Score ->  - 39.80\n",
      "(4500, 31)\n",
      "Fold - 4 - SVM Accuracy Score ->  - 42.20\n",
      "(4500, 31)\n",
      "Fold - 5 - SVM Accuracy Score ->  - 41.80\n",
      "(4500, 31)\n",
      "Fold - 6 - SVM Accuracy Score ->  - 40.00\n",
      "(4500, 31)\n",
      "Fold - 7 - SVM Accuracy Score ->  - 39.40\n",
      "(4500, 31)\n",
      "Fold - 8 - SVM Accuracy Score ->  - 37.00\n",
      "(4500, 31)\n",
      "Fold - 9 - SVM Accuracy Score ->  - 40.20\n",
      "(4500, 31)\n",
      "Fold - 10 - SVM Accuracy Score ->  - 33.80\n",
      "Mean 39.30 Std 2.29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = dataset['pos_questions'],dataset['a']\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "tfidf.fit(X)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "accuracies = []\n",
    "for train_index, test_index in cv.split(X):\n",
    "    fold += 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    y_train_e = le.transform(y_train)\n",
    "    y_test_e = le.transform(y_test)\n",
    "    \n",
    "    X_train_tfidf = tfidf.transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    print(X_train_tfidf.shape)\n",
    "    \n",
    "    SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "    SVM.fit(X_train_tfidf,y_train_e)\n",
    "    predictions_SVM = SVM.predict(X_test_tfidf)\n",
    "    acc = accuracy_score(predictions_SVM, y_test_e)*100\n",
    "    accuracies.append(acc)\n",
    "    print(\"Fold - {} - {} - {:.2f}\".format(fold, \"SVM Accuracy Score -> \",acc))\n",
    "    \n",
    "print(\"Mean {:.2f} Std {:.2f}\".format(np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Evauluation on Different Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def PRC_matrics(y_test, prediction):\n",
    "    # calculate prediction\n",
    "    precision = precision_score(y_test, prediction, labels=[1,2], average='micro')*100\n",
    "    print('Precision: %.3f' % precision)\n",
    "\n",
    "    # calculate recall\n",
    "    recall = recall_score(y_test, prediction, labels=[1,2], average='micro')*100\n",
    "    print('Recall: %.3f' % recall)\n",
    "    \n",
    "    # calculate score\n",
    "#     score = f1_score(y_test, prediction, average='micro')\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    print('F-Measure: %.3f' % f1_score)\n",
    "    \n",
    "    \n",
    "    acc = accuracy_score(y_test, prediction)*100\n",
    "#     tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
    "#     acc2 = (tn + tp)*100/(tn + fp + fn + tp)\n",
    "    print('Accuracy score: %.3f' % acc)\n",
    "    \n",
    "    \n",
    "    cm = confusion_matrix(y_test, prediction)\n",
    "    print(\"Confustion matrix: \\n{}\".format(cm))\n",
    "    \n",
    "    return precision, recall, f1_score, acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - A traditional ML classifier s.a. SVM or Logistic Regression with at least 5  of the features mentioned in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 26)\n",
      "(5000, 322)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5000, 5448)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from scipy.sparse import coo_matrix, csr_matrix, hstack\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(dataset['a'])\n",
    "\n",
    "X_lem = dataset['lem_questions']\n",
    "tfidf_lem = TfidfVectorizer(max_features=5000)\n",
    "tfidf_lem.fit(X_lem)\n",
    "\n",
    "X_pos = dataset['pos_questions']\n",
    "\n",
    "X_ne = dataset['ne_questions']\n",
    "\n",
    "XX = csr_matrix(hstack([tfidf_lem.transform(X_lem) ,get_count_vect(X_pos), get_count_vect(X_ne), head_words_vector]))\n",
    "\n",
    "XX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - Train with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 5448)\n",
      "Fold - 1 - SVM Accuracy Score ->  - 78.20\n",
      "(4500, 5448)\n",
      "Fold - 2 - SVM Accuracy Score ->  - 80.60\n",
      "(4500, 5448)\n",
      "Fold - 3 - SVM Accuracy Score ->  - 78.60\n",
      "(4500, 5448)\n",
      "Fold - 4 - SVM Accuracy Score ->  - 80.80\n",
      "(4500, 5448)\n",
      "Fold - 5 - SVM Accuracy Score ->  - 80.60\n",
      "(4500, 5448)\n",
      "Fold - 6 - SVM Accuracy Score ->  - 81.80\n",
      "(4500, 5448)\n",
      "Fold - 7 - SVM Accuracy Score ->  - 80.80\n",
      "(4500, 5448)\n",
      "Fold - 8 - SVM Accuracy Score ->  - 78.60\n",
      "(4500, 5448)\n",
      "Fold - 9 - SVM Accuracy Score ->  - 79.80\n",
      "(4500, 5448)\n",
      "Fold - 10 - SVM Accuracy Score ->  - 77.20\n",
      "Mean 79.70 Std 1.39\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "accuracies = []\n",
    "for train_index, test_index in cv.split(XX):\n",
    "    fold += 1\n",
    "    X_train, X_test = XX[train_index], XX[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    print(X_train.shape)\n",
    "\n",
    "    \n",
    "    SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "    SVM.fit(X_train,y_train)\n",
    "    predictions_SVM1 = SVM.predict(X_test)\n",
    "    acc = accuracy_score(predictions_SVM1, y_test)*100\n",
    "    accuracies.append(acc)\n",
    "    print(\"Fold - {} - {} - {:.2f}\".format(fold, \"SVM Accuracy Score -> \",acc))\n",
    "    \n",
    "print(\"Mean {:.2f} Std {:.2f}\".format(np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 85.882\n",
      "Recall: 73.737\n",
      "F-Measure: 79.348\n",
      "Accuracy score: 77.200\n",
      "Confustion matrix: \n",
      "[[61  0  2  6  0  7  0]\n",
      " [ 0 12  1  2  0  8  0]\n",
      " [ 3  1 47  4  0  5  0]\n",
      " [ 3  1  1 81  9 17  0]\n",
      " [ 2  1  0 10 74 11  0]\n",
      " [ 1  0  0 13  4 96  0]\n",
      " [ 0  0  0  2  0  0 15]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(85.88235294117646, 73.73737373737373, 79.34782608695652, 77.2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRC_matrics(y_test, predictions_SVM1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim Doc2Vec - Using Sentence Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(dataset['questions'])]\n",
    "model = Doc2Vec(documents, vector_size=1000, window=2, min_count=1, workers=4)\n",
    "\n",
    "def doc2vec(x):\n",
    "    return np.array(model.infer_vector(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec('hello world').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _id = 3\n",
    "# vector = model.infer_vector(dataset['questions'][_id].split(' '))\n",
    "# print(vector)\n",
    "# print(dataset['questions'][_id])\n",
    "\n",
    "dataset['doc2vec_questions'] = [doc2vec(question) for question in dataset['questions']]\n",
    "dataset['doc2vec_questions'][test_id]\n",
    "dataset['doc2vec_questions'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 1000)\n",
      "(4500,)\n",
      "Fold - 1 - SVM Accuracy Score ->  - 21.20\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 21.200\n",
      "Confustion matrix: \n",
      "[[  0   0   0  81   0   0   0]\n",
      " [  0   0   0  25   0   0   0]\n",
      " [  0   0   0  56   0   0   0]\n",
      " [  0   0   0 106   0   0   0]\n",
      " [  0   0   0  96   0   0   0]\n",
      " [  0   0   0 118   0   0   0]\n",
      " [  0   0   0  18   0   0   0]]\n",
      "(4500, 1000)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 2 - SVM Accuracy Score ->  - 27.00\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 27.000\n",
      "Confustion matrix: \n",
      "[[ 0  0  0 18  0 64  0  0]\n",
      " [ 0  0  0  4  0 21  0  0]\n",
      " [ 0  0  0 10  0 29  0  0]\n",
      " [ 0  0  0 45  0 79  0  0]\n",
      " [ 0  0  0 16  0 78  0  0]\n",
      " [ 0  0  0 20  0 90  0  0]\n",
      " [ 0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  2  0 23  0  0]]\n",
      "(4500, 1000)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 3 - SVM Accuracy Score ->  - 26.00\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 26.000\n",
      "Confustion matrix: \n",
      "[[ 0  0  0 13  0  0 59  0]\n",
      " [ 0  0  0  3  0  0 13  0]\n",
      " [ 0  0  0  7  0  0 45  0]\n",
      " [ 0  0  0 31  0  0 94  0]\n",
      " [ 0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0 13  0  0 85  0]\n",
      " [ 0  0  0 21  0  0 99  0]\n",
      " [ 0  0  0  1  0  0 15  0]]\n",
      "(4500, 1000)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 4 - SVM Accuracy Score ->  - 25.80\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 25.800\n",
      "Confustion matrix: \n",
      "[[ 0  0  0 10  0 60  0]\n",
      " [ 0  0  0  3  0 21  0]\n",
      " [ 0  0  0  8  0 49  0]\n",
      " [ 0  0  0 45  0 79  0]\n",
      " [ 0  0  0 24  0 78  0]\n",
      " [ 0  0  0 22  0 84  0]\n",
      " [ 0  0  0  1  0 16  0]]\n",
      "(4500, 1000)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 5 - SVM Accuracy Score ->  - 23.80\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 23.800\n",
      "Confustion matrix: \n",
      "[[ 0  0  0  8  0 49  0]\n",
      " [ 0  0  0  5  0 25  0]\n",
      " [ 0  0  0 15  0 34  0]\n",
      " [ 0  0  0 33  0 92  0]\n",
      " [ 0  0  0 25  0 85  0]\n",
      " [ 0  0  0 28  0 86  0]\n",
      " [ 0  0  0  1  0 14  0]]\n",
      "(4500, 1000)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 6 - SVM Accuracy Score ->  - 23.60\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 23.600\n",
      "Confustion matrix: \n",
      "[[  0   0   0  13   0  46   0]\n",
      " [  0   0   0   4   0  10   0]\n",
      " [  0   0   0   9   0  41   0]\n",
      " [  0   0   0  35   0 113   0]\n",
      " [  0   0   0  22   0  88   0]\n",
      " [  0   0   0  18   0  83   0]\n",
      " [  0   0   0   4   0  14   0]]\n",
      "(4500, 1000)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 7 - SVM Accuracy Score ->  - 22.00\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 22.000\n",
      "Confustion matrix: \n",
      "[[  0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0  89   0   0   0]\n",
      " [  0   0   0   0  24   0   0   0]\n",
      " [  0   0   0   0  43   0   0   0]\n",
      " [  0   0   0   0 110   0   0   0]\n",
      " [  0   0   0   0  98   0   0   0]\n",
      " [  0   0   0   0 120   0   0   0]\n",
      " [  0   0   0   0  15   0   0   0]]\n",
      "(4500, 1000)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 8 - SVM Accuracy Score ->  - 24.40\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 24.400\n",
      "Confustion matrix: \n",
      "[[ 0  0  0 16  0  0 47  0]\n",
      " [ 0  0  0  2  0  0 14  0]\n",
      " [ 0  0  0 11  0  0 50  0]\n",
      " [ 0  0  0 30  0  0 87  0]\n",
      " [ 0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0 23  0  0 87  0]\n",
      " [ 0  0  0 23  0  0 92  0]\n",
      " [ 0  0  0  0  0  0 17  0]]\n",
      "(4500, 1000)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 9 - SVM Accuracy Score ->  - 26.00\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 26.000\n",
      "Confustion matrix: \n",
      "[[ 0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0 13  0  0 58  0]\n",
      " [ 0  0  0  0  2  0  0 15  0]\n",
      " [ 0  0  0  0  6  0  0 48  0]\n",
      " [ 0  0  0  0 31  0  0 95  0]\n",
      " [ 0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0 17  0  0 78  0]\n",
      " [ 0  0  0  0 22  0  0 99  0]\n",
      " [ 0  0  0  0  2  0  0 12  0]]\n",
      "(4500, 1000)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 10 - SVM Accuracy Score ->  - 23.40\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 23.400\n",
      "Confustion matrix: \n",
      "[[ 0  0  0 20  0 56  0]\n",
      " [ 0  0  0  5  0 18  0]\n",
      " [ 0  0  0 11  0 49  0]\n",
      " [ 0  0  0 23  0 89  0]\n",
      " [ 0  0  0 19  0 79  0]\n",
      " [ 0  0  0 20  0 94  0]\n",
      " [ 0  0  0  1  0 16  0]]\n",
      "Mean 24.32 Std 1.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_doc2vec = np.array([doc2vec(question) for question in dataset['questions']])\n",
    "le = LabelEncoder()\n",
    "y_doc2vec = le.fit_transform(dataset['a'])\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "accuracies = []\n",
    "for train_index, test_index in cv.split(X_doc2vec):\n",
    "    fold += 1\n",
    "    X_train, X_test = X_doc2vec[train_index], X_doc2vec[test_index]\n",
    "    y_train, y_test = y_doc2vec[train_index], y_doc2vec[test_index]\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "    SVM.fit(X_train,y_train)\n",
    "    predictions_SVM = SVM.predict(X_test)\n",
    "    acc = accuracy_score(predictions_SVM, y_test)*100\n",
    "    accuracies.append(acc)\n",
    "    print(\"Fold - {} - {} - {:.2f}\".format(fold, \"SVM Accuracy Score -> \",acc))\n",
    "    PRC_matrics(y_test, predictions_SVM)\n",
    "    \n",
    "print(\"Mean {:.2f} Std {:.2f}\".format(np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 7, 1, 6, 1, 4, 9, 7])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"fasttext_skipgram_travel_questions.bin\" - model loaded\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import os\n",
    "model_name='fasttext_skipgram_travel_questions.bin'\n",
    "\n",
    "if not os.path.exists(model_name):\n",
    "    dataset['questions'].to_csv('questions.txt', sep='.', header=False, index=False)\n",
    "    model_fasttext = fasttext.train_unsupervised('questions.txt', model='skipgram')\n",
    "    model_fasttext.save_model(model_name)\n",
    "    print(\"Model saved as {}\".format(model_name))\n",
    "else:\n",
    "    print(\"\\\"{}\\\" - model loaded\".format(model_name))\n",
    "    model_fasttext = fasttext.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fasttext.words\n",
    "\n",
    "len(model_fasttext.get_word_vector(\"the\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_text_mean_transform(X):\n",
    "    words = X.split(' ')    \n",
    "    return np.mean([model_fasttext.get_word_vector(w) for w in words if w in model_fasttext.words]\n",
    "                    or [np.zeros(100)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_text_first_x_words(X, length):\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "    X_lstm = pad_sequences(X, maxlen=length)\n",
    "    \n",
    "    words = X.split(' ')    \n",
    "    return np.mean([model_fasttext.get_word_vector(w) for w in words if w in model_fasttext.words]\n",
    "                    or [np.zeros(100)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = 'the jaya'\n",
    "# length = 5\n",
    "# pad_sequences(inp.split(' '), maxlen=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(fast_text_mean_transform('dulan jaya'))\n",
    "# fast_text_mean_transform('the jaya')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['doc2fast_questions'] = [fast_text_mean_transform(question) for question in dataset['questions']]\n",
    "dataset['doc2fast_questions'][test_id]\n",
    "dataset['doc2fast_questions'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 100)\n",
      "(4500, 100)\n",
      "(4500,)\n",
      "Fold - 1 - SVM Accuracy Score ->  - 21.20\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 21.200\n",
      "Confustion matrix: \n",
      "[[  0   0   0  81   0   0   0]\n",
      " [  0   0   0  25   0   0   0]\n",
      " [  0   0   0  56   0   0   0]\n",
      " [  0   0   0 105   1   0   0]\n",
      " [  0   0   0  95   1   0   0]\n",
      " [  0   0   0 118   0   0   0]\n",
      " [  0   0   0  18   0   0   0]]\n",
      "(4500, 100)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 2 - SVM Accuracy Score ->  - 24.80\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 24.800\n",
      "Confustion matrix: \n",
      "[[  0   0   0  82   0   0   0   0]\n",
      " [  0   0   0  25   0   0   0   0]\n",
      " [  0   0   0  39   0   0   0   0]\n",
      " [  0   0   0 124   0   0   0   0]\n",
      " [  0   0   0  94   0   0   0   0]\n",
      " [  0   0   0 110   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0]\n",
      " [  0   0   0  25   0   0   0   0]]\n",
      "(4500, 100)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 3 - SVM Accuracy Score ->  - 24.80\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 24.800\n",
      "Confustion matrix: \n",
      "[[  0   0   0  72   0   0   0   0]\n",
      " [  0   0   0  16   0   0   0   0]\n",
      " [  0   0   0  52   0   0   0   0]\n",
      " [  0   0   0 124   0   1   0   0]\n",
      " [  0   0   0   1   0   0   0   0]\n",
      " [  0   0   0  98   0   0   0   0]\n",
      " [  0   0   0 120   0   0   0   0]\n",
      " [  0   0   0  16   0   0   0   0]]\n",
      "(4500, 100)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 4 - SVM Accuracy Score ->  - 24.80\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 24.800\n",
      "Confustion matrix: \n",
      "[[  0   0   0  70   0   0   0]\n",
      " [  0   0   0  24   0   0   0]\n",
      " [  0   0   0  57   0   0   0]\n",
      " [  0   0   0 124   0   0   0]\n",
      " [  0   0   0 102   0   0   0]\n",
      " [  0   0   0 106   0   0   0]\n",
      " [  0   0   0  17   0   0   0]]\n",
      "(4500, 100)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 5 - SVM Accuracy Score ->  - 25.00\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 25.000\n",
      "Confustion matrix: \n",
      "[[  0   0   0  57   0   0   0]\n",
      " [  0   0   0  30   0   0   0]\n",
      " [  0   0   0  49   0   0   0]\n",
      " [  0   0   0 125   0   0   0]\n",
      " [  0   0   0 110   0   0   0]\n",
      " [  0   0   0 114   0   0   0]\n",
      " [  0   0   0  15   0   0   0]]\n",
      "(4500, 100)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 6 - SVM Accuracy Score ->  - 29.60\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 29.600\n",
      "Confustion matrix: \n",
      "[[  0   0   0  59   0   0   0]\n",
      " [  0   0   0  14   0   0   0]\n",
      " [  0   0   0  50   0   0   0]\n",
      " [  0   0   0 148   0   0   0]\n",
      " [  0   0   0 110   0   0   0]\n",
      " [  0   0   0 101   0   0   0]\n",
      " [  0   0   0  18   0   0   0]]\n",
      "(4500, 100)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 7 - SVM Accuracy Score ->  - 22.00\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 22.000\n",
      "Confustion matrix: \n",
      "[[  0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0  89   0   0   0]\n",
      " [  0   0   0   0  24   0   0   0]\n",
      " [  0   0   0   0  43   0   0   0]\n",
      " [  0   0   0   0 110   0   0   0]\n",
      " [  0   0   0   0  98   0   0   0]\n",
      " [  0   0   0   0 120   0   0   0]\n",
      " [  0   0   0   0  15   0   0   0]]\n",
      "(4500, 100)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 8 - SVM Accuracy Score ->  - 23.40\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 23.400\n",
      "Confustion matrix: \n",
      "[[  0   0   0  62   0   1   0   0]\n",
      " [  0   0   0  16   0   0   0   0]\n",
      " [  0   0   0  61   0   0   0   0]\n",
      " [  0   0   0 117   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0]\n",
      " [  0   0   0 110   0   0   0   0]\n",
      " [  0   0   0 115   0   0   0   0]\n",
      " [  0   0   0  17   0   0   0   0]]\n",
      "(4500, 100)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 9 - SVM Accuracy Score ->  - 25.20\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 25.200\n",
      "Confustion matrix: \n",
      "[[  0   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0  71   0   0   0   0]\n",
      " [  0   0   0   0  17   0   0   0   0]\n",
      " [  0   0   0   0  54   0   0   0   0]\n",
      " [  0   0   0   0 126   0   0   0   0]\n",
      " [  0   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0  95   0   0   0   0]\n",
      " [  0   0   0   0 121   0   0   0   0]\n",
      " [  0   0   0   0  14   0   0   0   0]]\n",
      "(4500, 100)\n",
      "(4500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 10 - SVM Accuracy Score ->  - 22.40\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: nan\n",
      "Accuracy score: 22.400\n",
      "Confustion matrix: \n",
      "[[  0   0   0  74   2   0   0]\n",
      " [  0   0   0  23   0   0   0]\n",
      " [  0   0   0  60   0   0   0]\n",
      " [  0   0   0 112   0   0   0]\n",
      " [  0   0   0  98   0   0   0]\n",
      " [  0   0   0 114   0   0   0]\n",
      " [  0   0   0  17   0   0   0]]\n",
      "Mean 24.32 Std 2.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_doc2fast = np.array([fast_text_mean_transform(question) for question in dataset['questions']])\n",
    "le = LabelEncoder()\n",
    "y_doc2fast = le.fit_transform(dataset['a'])\n",
    "\n",
    "print(X_doc2fast.shape)\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "accuracies = []\n",
    "for train_index, test_index in cv.split(X_doc2fast):\n",
    "    fold += 1\n",
    "    X_train, X_test = X_doc2fast[train_index], X_doc2fast[test_index]\n",
    "    y_train, y_test = y_doc2fast[train_index], y_doc2fast[test_index]\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "    SVM.fit(X_train,y_train)\n",
    "    predictions_SVM = SVM.predict(X_test)\n",
    "    acc = accuracy_score(predictions_SVM, y_test)*100\n",
    "    accuracies.append(acc)\n",
    "    print(\"Fold - {} - {} - {:.2f}\".format(fold, \"SVM Accuracy Score -> \",acc))\n",
    "    PRC_matrics(y_test, predictions_SVM)\n",
    "    \n",
    "print(\"Mean {:.2f} Std {:.2f}\".format(np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_SVM[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRC_matrics(y_test, predictions_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a word Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - A NN classifier s.a. an LSTM for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 5000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 25\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 160\n",
    "epochs = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5582 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, split=' ')\n",
    "tokenizer.fit_on_texts(dataset['questions'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 7, 2, 321, 105, 31, 1837, 17, 68, 9, 20, 71, 6, 194, 48, 32, 22, 376, 111]\n",
      "Shape of data tensor: (5000, 25)\n",
      "Shape of label tensor: (5000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4, 7, 2, 321, 105, 31, 1837, 17, 68, 9, 20, 71, 6, 194, 48, 32, 22, 376, 111]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X = tokenizer.texts_to_sequences(dataset['questions'].values)\n",
    "print(X[0])\n",
    "X_lstm = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X_lstm.shape)\n",
    "\n",
    "y_nn = pd.get_dummies(dataset['a']).values\n",
    "print('Shape of label tensor:', y_nn.shape)\n",
    "\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 25, 160)           800000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 25, 160)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 196)               279888    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1970      \n",
      "=================================================================\n",
      "Total params: 1,081,858\n",
      "Trainable params: 1,081,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f3e40471790>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "def get_lstm_model(verbose=0):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_lstm.shape[1]))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(LSTM(196, dropout=0.2, recurrent_dropout=0.2))\n",
    "    # model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    epochs = 5\n",
    "    batch_size = 64\n",
    "    \n",
    "    if verbose == 1:\n",
    "        print(model.summary())\n",
    "    return model\n",
    "\n",
    "get_lstm_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 25) (4500, 10)\n",
      "(500, 25) (500, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_lstm,y_nn, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 3s 52ms/step - loss: 1.8205 - accuracy: 0.2765 - val_loss: 1.7947 - val_accuracy: 0.1511\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 3s 48ms/step - loss: 1.1693 - accuracy: 0.5800 - val_loss: 1.1670 - val_accuracy: 0.6044\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 3s 49ms/step - loss: 0.5660 - accuracy: 0.8195 - val_loss: 0.9370 - val_accuracy: 0.7044\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 5s 77ms/step - loss: 0.2955 - accuracy: 0.9116 - val_loss: 0.8026 - val_accuracy: 0.7778\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.1688 - accuracy: 0.9553 - val_loss: 0.9209 - val_accuracy: 0.7422\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 3s 51ms/step - loss: 0.1019 - accuracy: 0.9731 - val_loss: 0.9330 - val_accuracy: 0.7311\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 4s 61ms/step - loss: 0.0751 - accuracy: 0.9793 - val_loss: 0.8923 - val_accuracy: 0.7489\n",
      "Precision: 82.075\n",
      "Recall: 72.500\n",
      "F-Measure: 76.991\n",
      "Accuracy score: 81.800\n",
      "Confustion matrix: \n",
      "[[69  0  3  4  0  7  1]\n",
      " [ 1 18  6  0  0 10  1]\n",
      " [ 1  1 43  1  0  0  0]\n",
      " [ 5  1  3 92  4 12  1]\n",
      " [ 3  1  1  3 90  5  0]\n",
      " [ 2  4  0  4  1 84  2]\n",
      " [ 0  0  0  2  1  0 13]]\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 1.8196 - accuracy: 0.2696 - val_loss: 1.7665 - val_accuracy: 0.1244\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 3s 50ms/step - loss: 1.3351 - accuracy: 0.5094 - val_loss: 1.4642 - val_accuracy: 0.5067\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 4s 63ms/step - loss: 0.6866 - accuracy: 0.7780 - val_loss: 0.9997 - val_accuracy: 0.6733\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 4s 60ms/step - loss: 0.3725 - accuracy: 0.8825 - val_loss: 0.7006 - val_accuracy: 0.7978\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.1864 - accuracy: 0.9499 - val_loss: 1.0887 - val_accuracy: 0.6578\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.1151 - accuracy: 0.9699 - val_loss: 0.6979 - val_accuracy: 0.7889\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 4s 66ms/step - loss: 0.0684 - accuracy: 0.9825 - val_loss: 0.8620 - val_accuracy: 0.7600\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 4s 64ms/step - loss: 0.0552 - accuracy: 0.9872 - val_loss: 0.9092 - val_accuracy: 0.7244\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.0513 - accuracy: 0.9862 - val_loss: 0.8886 - val_accuracy: 0.7422\n",
      "Precision: 84.112\n",
      "Recall: 85.714\n",
      "F-Measure: 84.906\n",
      "Accuracy score: 83.200\n",
      "Confustion matrix: \n",
      "[[ 75   2   3   3   2   5   0   0]\n",
      " [  0  15   0   0   0   0   0   0]\n",
      " [  1   0  34   1   0   1   0   0]\n",
      " [  5   0   1 108  14  10   0   4]\n",
      " [  0   0   0   6  74   2   0   0]\n",
      " [  1   8   1   6   4  91   1   2]\n",
      " [  0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0  19]]\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 3s 54ms/step - loss: 1.7829 - accuracy: 0.2827 - val_loss: 1.8446 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 4s 55ms/step - loss: 1.2318 - accuracy: 0.5272 - val_loss: 1.4977 - val_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 4s 55ms/step - loss: 0.6751 - accuracy: 0.7788 - val_loss: 0.7729 - val_accuracy: 0.7689\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.3425 - accuracy: 0.8970 - val_loss: 0.7507 - val_accuracy: 0.7844\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 3s 54ms/step - loss: 0.1952 - accuracy: 0.9464 - val_loss: 1.0072 - val_accuracy: 0.7156\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 3s 51ms/step - loss: 0.1235 - accuracy: 0.9664 - val_loss: 0.7753 - val_accuracy: 0.7578\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 3s 52ms/step - loss: 0.0777 - accuracy: 0.9844 - val_loss: 0.9038 - val_accuracy: 0.7733\n",
      "Precision: 77.273\n",
      "Recall: 77.273\n",
      "F-Measure: 77.273\n",
      "Accuracy score: 79.600\n",
      "Confustion matrix: \n",
      "[[56  0  0  5  0  2  2  0]\n",
      " [ 0 12  3  3  0  0  5  0]\n",
      " [ 2  1 47  0  0  0  2  1]\n",
      " [ 9  1  0 96  1  7 20  2]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  6  0 88  4  0]\n",
      " [ 4  1  2 12  0  0 87  1]\n",
      " [ 0  0  0  3  0  1  0 12]]\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 1.8178 - accuracy: 0.2568 - val_loss: 1.7290 - val_accuracy: 0.5800\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 3s 52ms/step - loss: 1.3516 - accuracy: 0.4736 - val_loss: 1.4958 - val_accuracy: 0.4800\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.7672 - accuracy: 0.7575 - val_loss: 1.0470 - val_accuracy: 0.6533\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.3799 - accuracy: 0.8874 - val_loss: 0.7451 - val_accuracy: 0.7622\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 4s 60ms/step - loss: 0.2074 - accuracy: 0.9437 - val_loss: 0.8536 - val_accuracy: 0.7378\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.1296 - accuracy: 0.9681 - val_loss: 0.7574 - val_accuracy: 0.7689\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 0.0800 - accuracy: 0.9775 - val_loss: 0.6862 - val_accuracy: 0.7978\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 0.0537 - accuracy: 0.9867 - val_loss: 0.8466 - val_accuracy: 0.7756\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 4s 61ms/step - loss: 0.0385 - accuracy: 0.9906 - val_loss: 0.8556 - val_accuracy: 0.7733\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0252 - accuracy: 0.9943 - val_loss: 0.8821 - val_accuracy: 0.7600\n",
      "Precision: 73.404\n",
      "Recall: 82.143\n",
      "F-Measure: 77.528\n",
      "Accuracy score: 80.800\n",
      "Confustion matrix: \n",
      "[[58  2  3  4  1  2  0]\n",
      " [ 1 11  0  0  0  1  1]\n",
      " [ 2  2 50  1  1  2  0]\n",
      " [ 4  3  2 98  7 10  3]\n",
      " [ 1  0  0  6 87  4  0]\n",
      " [ 4  6  2 14  6 87  0]\n",
      " [ 0  0  0  1  0  0 13]]\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 4s 62ms/step - loss: 1.8182 - accuracy: 0.2822 - val_loss: 1.8049 - val_accuracy: 0.1667\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 4s 60ms/step - loss: 1.3277 - accuracy: 0.5015 - val_loss: 1.4009 - val_accuracy: 0.4956\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 4s 61ms/step - loss: 0.6723 - accuracy: 0.7857 - val_loss: 0.8736 - val_accuracy: 0.6844\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 4s 60ms/step - loss: 0.3409 - accuracy: 0.8975 - val_loss: 0.8621 - val_accuracy: 0.7444\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 0.1780 - accuracy: 0.9499 - val_loss: 0.7102 - val_accuracy: 0.7556\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 4s 60ms/step - loss: 0.1214 - accuracy: 0.9652 - val_loss: 0.7772 - val_accuracy: 0.7578\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0778 - accuracy: 0.9805 - val_loss: 0.7144 - val_accuracy: 0.7911\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0494 - accuracy: 0.9867 - val_loss: 0.7998 - val_accuracy: 0.7511\n",
      "Precision: 79.310\n",
      "Recall: 76.667\n",
      "F-Measure: 77.966\n",
      "Accuracy score: 78.800\n",
      "Confustion matrix: \n",
      "[[ 49   0   0   4   3   8   0]\n",
      " [  1  20   0   1   1   3   0]\n",
      " [  3   1  42   2   0   3   0]\n",
      " [  3   1   7 100   7  16   3]\n",
      " [  0   1   0   7  93   3   0]\n",
      " [  1   7   0  11   5  79   1]\n",
      " [  0   0   0   0   1   2  11]]\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 1.8249 - accuracy: 0.2874 - val_loss: 1.9517 - val_accuracy: 0.1600\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 1.2078 - accuracy: 0.5664 - val_loss: 1.2582 - val_accuracy: 0.6022\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.5746 - accuracy: 0.8193 - val_loss: 0.8090 - val_accuracy: 0.7822\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.2945 - accuracy: 0.9210 - val_loss: 0.7583 - val_accuracy: 0.7800\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.1687 - accuracy: 0.9585 - val_loss: 0.7112 - val_accuracy: 0.8000\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.0979 - accuracy: 0.9751 - val_loss: 0.9231 - val_accuracy: 0.7467\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.0700 - accuracy: 0.9815 - val_loss: 0.8065 - val_accuracy: 0.7911\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.0476 - accuracy: 0.9881 - val_loss: 0.9779 - val_accuracy: 0.7467\n",
      "Precision: 83.562\n",
      "Recall: 72.619\n",
      "F-Measure: 77.707\n",
      "Accuracy score: 83.400\n",
      "Confustion matrix: \n",
      "[[ 51   1   0   9   1   5   1]\n",
      " [  2  10   0   0   1   3   0]\n",
      " [  2   0  48   2   2   4   0]\n",
      " [  3   0   0 115   5  10   0]\n",
      " [  0   0   0   8  99   1   1]\n",
      " [  1   3   2  14   2  78   0]\n",
      " [  0   0   0   0   0   0  16]]\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 1.8186 - accuracy: 0.2773 - val_loss: 1.9183 - val_accuracy: 0.1556\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 1.2447 - accuracy: 0.5617 - val_loss: 1.3325 - val_accuracy: 0.4956\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.5549 - accuracy: 0.8210 - val_loss: 0.6468 - val_accuracy: 0.8267\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.2760 - accuracy: 0.9165 - val_loss: 0.7243 - val_accuracy: 0.7733\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.1492 - accuracy: 0.9602 - val_loss: 0.7162 - val_accuracy: 0.7733\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0960 - accuracy: 0.9728 - val_loss: 0.6907 - val_accuracy: 0.7889\n",
      "Precision: 73.451\n",
      "Recall: 87.368\n",
      "F-Measure: 79.808\n",
      "Accuracy score: 80.600\n",
      "Confustion matrix: \n",
      "[[ 0  0  0  0  0  0  0  0]\n",
      " [ 0 72  0  0  5  1  2  0]\n",
      " [ 1  0 11  0  0  0  3  0]\n",
      " [ 0  0  6 41  3  0  5  0]\n",
      " [ 0  7  3  1 88  6 15  3]\n",
      " [ 0  2  0  1  6 88  2  1]\n",
      " [ 0  8  4  0  8  3 93  1]\n",
      " [ 0  0  0  0  0  0  0 10]]\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 1.8189 - accuracy: 0.2815 - val_loss: 1.9669 - val_accuracy: 0.1111\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 1.3437 - accuracy: 0.5002 - val_loss: 1.4810 - val_accuracy: 0.4689\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.6599 - accuracy: 0.7867 - val_loss: 0.8755 - val_accuracy: 0.7444\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.2961 - accuracy: 0.9121 - val_loss: 0.7918 - val_accuracy: 0.7400\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.1564 - accuracy: 0.9583 - val_loss: 0.6176 - val_accuracy: 0.8000\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.1121 - accuracy: 0.9701 - val_loss: 0.7905 - val_accuracy: 0.7822\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.0665 - accuracy: 0.9825 - val_loss: 0.7778 - val_accuracy: 0.7667\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.0418 - accuracy: 0.9909 - val_loss: 0.8431 - val_accuracy: 0.7511\n",
      "Precision: 87.342\n",
      "Recall: 75.000\n",
      "F-Measure: 80.702\n",
      "Accuracy score: 80.400\n",
      "Confustion matrix: \n",
      "[[57  0  0  7  1  2  5  0]\n",
      " [ 0 12  1  0  0  1  6  0]\n",
      " [ 1  1 56  1  0  0  1  0]\n",
      " [ 2  0  1 88  0  7 15  2]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 1  0  1  5  0 97  8  0]\n",
      " [ 2  3  2 14  0  3 80  3]\n",
      " [ 0  0  0  2  0  0  0 12]]\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 1.8114 - accuracy: 0.2805 - val_loss: 1.5949 - val_accuracy: 0.5756\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 1.2307 - accuracy: 0.5494 - val_loss: 1.3044 - val_accuracy: 0.6378\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.6467 - accuracy: 0.7827 - val_loss: 0.9679 - val_accuracy: 0.6956\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.3234 - accuracy: 0.9044 - val_loss: 1.0986 - val_accuracy: 0.6156\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.1783 - accuracy: 0.9464 - val_loss: 0.7869 - val_accuracy: 0.7556\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.0948 - accuracy: 0.9785 - val_loss: 0.7867 - val_accuracy: 0.7711\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.0701 - accuracy: 0.9805 - val_loss: 0.8112 - val_accuracy: 0.7711\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.0524 - accuracy: 0.9879 - val_loss: 0.9350 - val_accuracy: 0.7689\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.0383 - accuracy: 0.9899 - val_loss: 1.1464 - val_accuracy: 0.7178\n",
      "Precision: 80.682\n",
      "Recall: 73.196\n",
      "F-Measure: 76.757\n",
      "Accuracy score: 81.800\n",
      "Confustion matrix: \n",
      "[[  0   0   0   0   0   0   0   0   0]\n",
      " [  0  64   3   2   5   0   0  12   0]\n",
      " [  0   0   7   0   1   0   0   3   0]\n",
      " [  0   0   3  51   3   0   0   3   0]\n",
      " [  1   4   0   1 101   1  11  11   1]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   3   0  83   1   0]\n",
      " [  0   3   4   0  12   0   1  91   1]\n",
      " [  0   0   0   0   1   0   0   0  12]]\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 1.8263 - accuracy: 0.2793 - val_loss: 1.9089 - val_accuracy: 0.1378\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 1.2358 - accuracy: 0.5558 - val_loss: 1.4617 - val_accuracy: 0.4356\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.5977 - accuracy: 0.8106 - val_loss: 0.8184 - val_accuracy: 0.7622\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.3118 - accuracy: 0.9077 - val_loss: 0.8382 - val_accuracy: 0.7622\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.1676 - accuracy: 0.9543 - val_loss: 0.8136 - val_accuracy: 0.7778\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.1173 - accuracy: 0.9679 - val_loss: 0.7695 - val_accuracy: 0.7733\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.0743 - accuracy: 0.9793 - val_loss: 0.9374 - val_accuracy: 0.7222\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.0510 - accuracy: 0.9852 - val_loss: 0.9142 - val_accuracy: 0.7356\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.0441 - accuracy: 0.9889 - val_loss: 0.8932 - val_accuracy: 0.7889\n",
      "Precision: 76.768\n",
      "Recall: 89.412\n",
      "F-Measure: 82.609\n",
      "Accuracy score: 81.400\n",
      "Confustion matrix: \n",
      "[[65  0  1  3  1  1  0]\n",
      " [ 0 11  1  1  0  1  0]\n",
      " [ 1  1 52  2  0  0  0]\n",
      " [ 2  1  1 84  4  9  1]\n",
      " [ 0  0  0 10 82  4  0]\n",
      " [ 8 10  5 12 11 99  2]\n",
      " [ 0  0  0  0  0  0 14]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "accuracies = []\n",
    "for train_index, test_index in cv.split(X):\n",
    "    fold += 1\n",
    "    X_train, X_test = X_lstm[train_index], X_lstm[test_index]\n",
    "    y_train, y_test = y_nn[train_index], y_nn[test_index]\n",
    "    \n",
    "    model = get_lstm_model()\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    fine_pred = [np.argmax(p) for p in predictions]\n",
    "    fine_gt = [np.argmax(p) for p in y_test]\n",
    "\n",
    "    PRC_matrics(fine_pred, fine_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 32.323\n",
      "Recall: 34.409\n",
      "F-Measure: 3333.333\n",
      "Accuracy score: 25.000\n",
      "Confustion matrix: \n",
      "[[28  4  6 10  8 12  2]\n",
      " [ 1  4  7  5  3  2  1]\n",
      " [ 5  2 12 14  9  9  1]\n",
      " [15  5 12 34 28 27  2]\n",
      " [13  3  9 17 26 25  1]\n",
      " [13  4 14 31 20 35  9]\n",
      " [ 1  1  0  1  4  4  1]]\n"
     ]
    }
   ],
   "source": [
    "fine_pred = [np.argmax(p) for p in predictions]\n",
    "fine_gt = [np.argmax(p) for p in y_test]\n",
    "PRC_matrics(fine_pred, fine_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4. BONUS - experiment with a BERT-based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(dataset['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1, Total size: 423.26MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a bert tockenizer\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "os.environ['TFHUB_DOWNLOAD_PROGRESS'] = \"1\"\n",
    "\n",
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_reviews(text_reviews):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_questions = [tokenize_reviews(qu) for qu in dataset['questions'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_with_len = [[question, y[i], len(question)] for i, question in enumerate(tokenized_questions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_with_len[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(reviews_with_len)\n",
    "sorted_reviews_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_reviews_labels, output_types=(tf.int32, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(batched_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEXT_MODEL(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dimensions=128,\n",
    "                 cnn_filters=50,\n",
    "                 dnn_units=512,\n",
    "                 model_output_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 training=False,\n",
    "                 name=\"text_model\"):\n",
    "        super(TEXT_MODEL, self).__init__(name=name)\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocabulary_size,\n",
    "                                          embedding_dimensions)\n",
    "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=2,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=3,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=4,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.pool = layers.GlobalMaxPool1D()\n",
    "        \n",
    "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        if model_output_classes == 2:\n",
    "            self.last_dense = layers.Dense(units=1,\n",
    "                                           activation=\"sigmoid\")\n",
    "        else:\n",
    "            self.last_dense = layers.Dense(units=model_output_classes,\n",
    "                                           activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        l = self.embedding(inputs)\n",
    "        l_1 = self.cnn_layer1(l) \n",
    "        l_1 = self.pool(l_1) \n",
    "        l_2 = self.cnn_layer2(l) \n",
    "        l_2 = self.pool(l_2)\n",
    "        l_3 = self.cnn_layer3(l)\n",
    "        l_3 = self.pool(l_3) \n",
    "        \n",
    "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1) # (batch_size, 3 * cnn_filters)\n",
    "        concatenated = self.dense_1(concatenated)\n",
    "        concatenated = self.dropout(concatenated, training)\n",
    "        model_output = self.last_dense(concatenated)\n",
    "        \n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_LENGTH = len(tokenizer.vocab)\n",
    "EMB_DIM = 200\n",
    "CNN_FILTERS = 100\n",
    "DNN_UNITS = 256\n",
    "OUTPUT_CLASSES = 10\n",
    "\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "NB_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
    "#                         embedding_dimensions=EMB_DIM,\n",
    "#                         cnn_filters=CNN_FILTERS,\n",
    "#                         dnn_units=DNN_UNITS,\n",
    "#                         model_output_classes=OUTPUT_CLASSES,\n",
    "#                         dropout_rate=DROPOUT_RATE)\n",
    "\n",
    "def create_and_compile_bert():\n",
    "    text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
    "                            embedding_dimensions=EMB_DIM,\n",
    "                            cnn_filters=CNN_FILTERS,\n",
    "                            dnn_units=DNN_UNITS,\n",
    "                            model_output_classes=OUTPUT_CLASSES,\n",
    "                            dropout_rate=DROPOUT_RATE)\n",
    "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"sparse_categorical_accuracy\"])\n",
    "    \n",
    "    return text_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TEXT_MODEL at 0x7f3d1e794910>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_and_compile_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.PaddedBatchDataset"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batched_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "142/142 [==============================] - 12s 82ms/step - loss: 1.4120 - sparse_categorical_accuracy: 0.4774\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.4719 - sparse_categorical_accuracy: 0.8597\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.1391 - sparse_categorical_accuracy: 0.9624\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0409 - sparse_categorical_accuracy: 0.9918\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0167 - sparse_categorical_accuracy: 0.9971\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9989\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9989\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9989\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9991\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9996\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.9279 - sparse_categorical_accuracy: 0.8167\n",
      "[0.9278545379638672, 0.8166666626930237]\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 1.3830 - sparse_categorical_accuracy: 0.4867\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.4418 - sparse_categorical_accuracy: 0.8642\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.1329 - sparse_categorical_accuracy: 0.9633\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0379 - sparse_categorical_accuracy: 0.9920\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0172 - sparse_categorical_accuracy: 0.9969\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0107 - sparse_categorical_accuracy: 0.9980\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9980\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9991\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9996\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9998\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8529 - sparse_categorical_accuracy: 0.8208\n",
      "[0.852890133857727, 0.8208333253860474]\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 1.3938 - sparse_categorical_accuracy: 0.4836\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.4497 - sparse_categorical_accuracy: 0.8664\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.1328 - sparse_categorical_accuracy: 0.9664\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0376 - sparse_categorical_accuracy: 0.9931\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0152 - sparse_categorical_accuracy: 0.9980\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9985\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9989\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9987\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9991\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9996\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.9205 - sparse_categorical_accuracy: 0.8104\n",
      "[0.9204831719398499, 0.8104166388511658]\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 1.4130 - sparse_categorical_accuracy: 0.4730\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.4617 - sparse_categorical_accuracy: 0.8606\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.1363 - sparse_categorical_accuracy: 0.9639\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0423 - sparse_categorical_accuracy: 0.9905\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0182 - sparse_categorical_accuracy: 0.9962\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9980\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9987\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9989\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.0019 - sparse_categorical_accuracy: 1.0000\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.9666 - sparse_categorical_accuracy: 0.8146\n",
      "[0.9666312336921692, 0.8145833611488342]\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 1.4022 - sparse_categorical_accuracy: 0.4796\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.4669 - sparse_categorical_accuracy: 0.8571\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.1440 - sparse_categorical_accuracy: 0.9628\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.0446 - sparse_categorical_accuracy: 0.9909\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0179 - sparse_categorical_accuracy: 0.9976\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9980\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9989\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9991\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0030 - sparse_categorical_accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9996\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8528 - sparse_categorical_accuracy: 0.8146\n",
      "[0.8528225421905518, 0.8145833611488342]\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 1.4243 - sparse_categorical_accuracy: 0.4679\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.4748 - sparse_categorical_accuracy: 0.8582\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.1499 - sparse_categorical_accuracy: 0.9597\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0465 - sparse_categorical_accuracy: 0.9909\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0210 - sparse_categorical_accuracy: 0.9969\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.0114 - sparse_categorical_accuracy: 0.9976\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 5s 32ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9987\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 5s 33ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9989\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 5s 32ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 4s 32ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9989\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.8965 - sparse_categorical_accuracy: 0.8042\n",
      "[0.896523654460907, 0.8041666746139526]\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 1.4055 - sparse_categorical_accuracy: 0.4777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "142/142 [==============================] - 5s 32ms/step - loss: 0.4559 - sparse_categorical_accuracy: 0.8635\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 5s 33ms/step - loss: 0.1490 - sparse_categorical_accuracy: 0.9608\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0448 - sparse_categorical_accuracy: 0.9914\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.0202 - sparse_categorical_accuracy: 0.9962\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0098 - sparse_categorical_accuracy: 0.9985\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9989\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9982\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9996\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.9065 - sparse_categorical_accuracy: 0.8125\n",
      "[0.9065108895301819, 0.8125]\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 1.3893 - sparse_categorical_accuracy: 0.4878\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.4638 - sparse_categorical_accuracy: 0.8600\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.1531 - sparse_categorical_accuracy: 0.9604\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.0449 - sparse_categorical_accuracy: 0.9916\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0181 - sparse_categorical_accuracy: 0.9969\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9980\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9987\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9996\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.9412 - sparse_categorical_accuracy: 0.8167\n",
      "[0.9411752223968506, 0.8166666626930237]\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 1.4379 - sparse_categorical_accuracy: 0.4573\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.4771 - sparse_categorical_accuracy: 0.8540\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.1408 - sparse_categorical_accuracy: 0.9608\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0464 - sparse_categorical_accuracy: 0.9920\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0203 - sparse_categorical_accuracy: 0.9962\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9982\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9989\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0030 - sparse_categorical_accuracy: 0.9991\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9998\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.8995 - sparse_categorical_accuracy: 0.8146\n",
      "[0.8994573950767517, 0.8145833611488342]\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 1.4355 - sparse_categorical_accuracy: 0.4573\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.4912 - sparse_categorical_accuracy: 0.8518\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.1615 - sparse_categorical_accuracy: 0.9542\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0513 - sparse_categorical_accuracy: 0.9889\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0217 - sparse_categorical_accuracy: 0.9958\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9985\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9989\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9989\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9987\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9996\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.8370 - sparse_categorical_accuracy: 0.8188\n",
      "[0.8370484709739685, 0.8187500238418579]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import math\n",
    "TOTAL_BATCHES = math.ceil(len(sorted_reviews_labels) / BATCH_SIZE)\n",
    "TEST_BATCHES = TOTAL_BATCHES // 10\n",
    "batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "    \n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "accuracies = []\n",
    "for i in range(10):\n",
    "    fold += 1\n",
    "    \n",
    "    text_model = create_and_compile_bert()\n",
    "    \n",
    "    # shuffel and take 10 batches\n",
    "    batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "    test_data = batched_dataset.take(TEST_BATCHES)\n",
    "    train_data = batched_dataset.skip(TEST_BATCHES)\n",
    "    \n",
    "\n",
    "    text_model.fit(train_data, epochs=NB_EPOCHS)\n",
    "    results = text_model.evaluate(test_data)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-c68ce269e8a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "np.array(test_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.3041423e-03 4.4251319e-06 4.9158145e-05 ... 1.1670458e-01\n",
      "  2.1933261e-05 3.3491149e-05]\n",
      " [1.8490636e-04 6.0688013e-05 3.4000166e-02 ... 6.0006059e-06\n",
      "  1.0600809e-07 1.7102753e-08]\n",
      " [1.0674372e-03 1.1785355e-04 3.4212761e-03 ... 2.1440899e-03\n",
      "  4.7785823e-05 8.0390555e-06]\n",
      " ...\n",
      " [4.4226599e-07 5.0554455e-08 1.8028316e-09 ... 1.2207782e-06\n",
      "  1.9355628e-08 2.3310758e-09]\n",
      " [9.5180400e-07 9.9906546e-01 6.4753972e-06 ... 9.4981534e-09\n",
      "  6.7950418e-10 1.4547613e-10]\n",
      " [4.3045085e-07 7.5500552e-08 2.4676950e-07 ... 9.9999833e-01\n",
      "  4.7554341e-08 3.7406920e-07]]\n"
     ]
    }
   ],
   "source": [
    "prediction = text_model.predict(test_data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 76.768\n",
      "Recall: 89.412\n",
      "F-Measure: 82.609\n",
      "Accuracy score: 81.400\n",
      "Confustion matrix: \n",
      "[[65  0  1  3  1  1  0]\n",
      " [ 0 11  1  1  0  1  0]\n",
      " [ 1  1 52  2  0  0  0]\n",
      " [ 2  1  1 84  4  9  1]\n",
      " [ 0  0  0 10 82  4  0]\n",
      " [ 8 10  5 12 11 99  2]\n",
      " [ 0  0  0  0  0  0 14]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(76.76767676767676, 89.41176470588236, 82.60869565217392, 81.39999999999999)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_pred = [np.argmax(p) for p in predictions]\n",
    "bert_gt = [np.argmax(p) for p in y_test]\n",
    "PRC_matrics(bert_pred, bert_gt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
