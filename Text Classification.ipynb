{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           questions    a       b\n",
      "0  What are the special things we (husband and me...  TTD  TTDSIG\n",
      "1  What are the companies which organize shark fe...  TTD  TTDOTH\n",
      "2  Is it safe for female traveller to go alone to...  TGU  TGUHEA\n",
      "3  What are the best places around Cape Town for ...  TTD  TTDSIG\n",
      "4  What are the best places to stay for a family ...  ACM  ACMOTH\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   questions  5000 non-null   object\n",
      " 1   a          5000 non-null   object\n",
      " 2   b          5000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 117.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "file_name = 'data/Travel-Dataset-5000--master/5000TravelQuestionsDataset.xlsx'\n",
    "col_names = ['questions', 'a', 'b']\n",
    "dataset = pd.read_excel(file_name, header=None, names=col_names)\n",
    "print(dataset.head())\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TTD', 'TGU', 'ACM', 'TRS', 'WTH', 'FOD', 'ENT', 'TGU\\n', 'TTD\\n',\n",
       "       '\\nENT'], dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['a'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TTDSIG', 'TTDOTH', 'TGUHEA', 'ACMOTH', 'TRSTRN', 'TGUBAN',\n",
       "       'WTHTMP', 'TGUNEI', 'TTDSPO', 'ACMAPA', 'TRSOTH', 'TRSAIR',\n",
       "       'TRSROU', 'TGUOTH', 'ACMRES', 'ACMBUN', 'TRSCRS', 'WTHDRC',\n",
       "       'TRSRNT', 'TGUTOP', 'FODOTH', 'TGUVIS', 'FODAUT', 'TTDTRI',\n",
       "       'TGUPLN', 'TRSTAX', 'WTHOTH', 'TRSBUS', 'ACMHOT', 'TGULUG',\n",
       "       'FODBAK', 'TTDSPA', 'FODBRE', 'TGUATT', 'ENTCLB', 'TGUAVE',\n",
       "       'TGUTEL', 'TGUCIG', 'TTDSHP', 'TRSTCD', 'ACMBEA', 'FODCOT',\n",
       "       'TGUAPT', 'TRSLIC', 'TGULAU', 'TTDGYM', 'FODCAT', 'FODBAR',\n",
       "       'TGUHOL', 'ENTFES', 'TGURUL', 'TGURES', 'WTHTMP\\n', 'ACMCAR',\n",
       "       'FODFMA', 'ENTSHW', 'TRSGAS', '\\nTGULAU', 'TRSOTH\\n', 'WTHSNW',\n",
       "       'ENTMUS', 'ENTSPO', 'FODBAK\\n', 'TRSAIR\\n', 'TGUWEB', 'TRSDRV',\n",
       "       'FODFCA', 'TGUCIG\\n', 'ENTOTH', 'TTDOTH\\n', 'WTHOTH\\n', 'TTDSIG\\n',\n",
       "       'TGUOTH\\n', 'TTDSHP\\n', 'TRSROU\\n', 'TTDSPO\\n', '\\nACMOTH',\n",
       "       'ACMOTH\\n', '\\nWTHOTH'], dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['b'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the special things we (husband and me) can do during a 5 day stay at Cape Town?'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['questions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the companies which organize shark feeding events for scuba divers?'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['questions'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the special things we (husband and me...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the companies which organize shark fe...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDOTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it safe for female traveller to go alone to...</td>\n",
       "      <td>TGU</td>\n",
       "      <td>TGUHEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the best places around Cape Town for ...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the best places to stay for a family ...</td>\n",
       "      <td>ACM</td>\n",
       "      <td>ACMOTH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions    a       b\n",
       "0  What are the special things we (husband and me...  TTD  TTDSIG\n",
       "1  What are the companies which organize shark fe...  TTD  TTDOTH\n",
       "2  Is it safe for female traveller to go alone to...  TGU  TGUHEA\n",
       "3  What are the best places around Cape Town for ...  TTD  TTDSIG\n",
       "4  What are the best places to stay for a family ...  ACM  ACMOTH"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   questions  5000 non-null   object\n",
      " 1   a          5000 non-null   object\n",
      " 2   b          5000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test_id = 1\n",
    "dataset['questions'].dropna(inplace=True)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the companies which organize shark feeding events for scuba divers?'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['questions'][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what are the companies which organize shark feeding events for scuba divers?'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lowercase(x):\n",
    "    return x.lower()\n",
    "\n",
    "dataset['questions'] = [lowercase(question) for question in dataset['questions']]\n",
    "dataset['questions'][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what are the companies which organize shark feeding events for scuba divers'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(x):\n",
    "    return \"\".join([char for char in x if char not in string.punctuation])\n",
    "\n",
    "dataset['questions'] = [remove_punctuation(question) for question in dataset['questions']]\n",
    "dataset['questions'][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# stop_words = stopwords.words('english')\n",
    "# from nltk import word_tokenize\n",
    "\n",
    "# def remove_stopwords(x):\n",
    "#     words = word_tokenize(x)\n",
    "#     return \" \".join([word for word in words if word not in stop_words])\n",
    "\n",
    "# dataset['questions'] = [remove_stopwords(question) for question in dataset['questions']]\n",
    "# dataset['questions'][test_id]\n",
    "# print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem.porter import PorterStemmer\n",
    "# porter = PorterStemmer()\n",
    "# def stemming(x):\n",
    "#     filtered_words = word_tokenize(x['questions'])\n",
    "#     stemmed = [porter.stem(word) for word in filtered_words]\n",
    "#     return \" \".join(stemmed)\n",
    "\n",
    "# dataset['questions'] = [remove_stopwords(question) for question in dataset['questions']]\n",
    "# dataset['questions'][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what are the company which organize shark feeding event for scuba diver'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(x):\n",
    "    filtered_words = word_tokenize(x)\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    return \" \".join(lemmatized)\n",
    "\n",
    "dataset['questions'] = [lemmatize(question) for question in dataset['questions']]\n",
    "dataset['questions'][test_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk import pos_tag\n",
    "# def pos_tagging(x):\n",
    "#     words = word_tokenize(x['questions'])\n",
    "#     return pos_tag(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM - Normal train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 1 - SVM Accuracy Score ->  - 82.8\n",
      "Fold - 2 - SVM Accuracy Score ->  - 84.0\n",
      "Fold - 3 - SVM Accuracy Score ->  - 81.0\n",
      "Fold - 4 - SVM Accuracy Score ->  - 82.39999999999999\n",
      "Fold - 5 - SVM Accuracy Score ->  - 83.2\n",
      "Fold - 6 - SVM Accuracy Score ->  - 83.2\n",
      "Fold - 7 - SVM Accuracy Score ->  - 84.0\n",
      "Fold - 8 - SVM Accuracy Score ->  - 84.0\n",
      "Fold - 9 - SVM Accuracy Score ->  - 82.19999999999999\n",
      "Fold - 10 - SVM Accuracy Score ->  - 82.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = dataset['questions'],dataset['a']\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "tfidf.fit(X)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "    \n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "fold = 0\n",
    "accuracies = []\n",
    "for train_index, test_index in cv.split(X):\n",
    "    fold += 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    y_train_e = le.transform(y_train)\n",
    "    y_test_e = le.transform(y_test)\n",
    "    \n",
    "    X_train_tfidf = Tfidf_vect.transform(X_train)\n",
    "    X_test_tfidf = Tfidf_vect.transform(X_test)\n",
    "    \n",
    "    SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "    SVM.fit(X_train_tfidf,y_train_e)\n",
    "    predictions_SVM = SVM.predict(X_test_tfidf)\n",
    "    acc = accuracy_score(predictions_SVM, y_test_e)*100\n",
    "    accuracies.append(acc)\n",
    "    print(\"Fold - {} - {} - {}\".format(fold, \"SVM Accuracy Score -> \",acc))\n",
    "    \n",
    "print(\"Mean {} Std {}\".format(np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[82.8,\n",
       " 84.0,\n",
       " 81.0,\n",
       " 82.39999999999999,\n",
       " 83.2,\n",
       " 83.2,\n",
       " 84.0,\n",
       " 84.0,\n",
       " 82.19999999999999,\n",
       " 82.8]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.std([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "data = ['data']\n",
    "model = gensim.models.Word2Vec(data, min_count=1, sg=1, window = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
